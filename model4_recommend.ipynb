{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후보군의 노래를 가져와서 \n",
    "\n",
    "    신나게 요리해본다\n",
    "\n",
    "\n",
    "another추천\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import scipy.sparse as spr\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_meta = pd.read_json('data/song_meta.json')\n",
    "train = pd.read_json('data/train.json')\n",
    "val = pd.read_json('data/val.json')\n",
    "test = pd.read_json('data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_tagtitle = pd.read_pickle('data/transfromation/tag_title_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_date_dict( song_meta ): # song_meta를 받아서 날짜와 매핑한다.\n",
    "    # 간혹 20050200 같은 놈들은 20050101\n",
    "    # 0 인놈들은 1990 으로 변경\n",
    "    a = []\n",
    "    for t in song_meta.issue_date:\n",
    "        try:\n",
    "            a.append(datetime.datetime.strptime( str(t) , '%Y%m%d' ).date())\n",
    "        except:\n",
    "            try:\n",
    "                a.append(datetime.datetime.strptime( str(t)[:4] , '%Y' ).date())\n",
    "            except:\n",
    "                a.append(datetime.datetime.strptime( '1990' , '%Y' ).date())\n",
    "    return dict(zip(song_meta.id , a))\n",
    "\n",
    "song_date = get_song_date_dict(song_meta) # \n",
    "\n",
    "def get_candidate( sim_dict , by = 'set' ):\n",
    "    \n",
    "    \"\"\" 후보군 뽑기\n",
    "    # val_songs , val \n",
    "    # val_tags , ply_tagtitle , val\n",
    "    # sim --> train + ply_tagtitle\n",
    "    # by --> set , count\n",
    "    \"\"\"\n",
    "    global song_date\n",
    "    global train\n",
    "    global val\n",
    "    global ply_tagtitle\n",
    "    val_songs = val.songs.values\n",
    "    val_tags = val.tags.values\n",
    "#     val_date = pd.to_datetime(val.updt_date).dt.date\n",
    "    \n",
    "    sim_ply = pd.merge( train[['id' , 'songs']] , ply_tagtitle , on = 'id' , how = 'left')\n",
    "    res =  {}\n",
    "    i = 0\n",
    "    for k in tqdm(sim_dict.keys()):\n",
    "        sim = sim_ply.loc[ sim_ply.id.isin( sim_dict[k] ) ]\n",
    "        if by == 'set':\n",
    "            cand_songs = list(set([ s for sgs in sim.songs for s in sgs if not(s in val_songs[i]) ]))  \n",
    "        elif by == 'count':\n",
    "            cand_songs = [ s for sgs in sim.songs for s in sgs if not(s in val_songs[i]) ]  \n",
    "# and (song_date[s] < val_date[i])]\n",
    "        cand_tags = [ t for tgs in sim.complex_col for t in tgs if not (t in val_tags[i]) ]\n",
    "        res[k] = { 'songs' : cand_songs  , 'tags' : cand_tags }\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "def filter_date( candi ):\n",
    "    global val\n",
    "    val_date = pd.to_datetime(val.updt_date).dt.date\n",
    "    j = 0 \n",
    "    for i in tqdm(candi):\n",
    "        candi[i]['songs'] = [ s for s in candi[i]['songs'] if song_date[s] <= val_date[j]]\n",
    "        j += 1\n",
    "    return candi\n",
    "\n",
    "def load_pickle( f_path ):\n",
    "    with open( f_path , 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3></h3>\n",
    "<h3></h3>\n",
    "\n",
    "**연관있는 플레이리스트를 담은 pickle 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sim = load_pickle( 'candi/res_ver34_song.pickle' )\n",
    "# w_sim = load_pickle( 'candi/res_ver34_word.pickle' )\n",
    "# sin_sim = load_pickle( 'candi/res_ver34_singer.pickle' )\n",
    "t_sim = load_pickle( 'candi/res_ver34_tag.pickle' )\n",
    "# g_sim = load_pickle( 'candi/res_ver34_gnr.pickle' )\n",
    "# ply_sim = load_pickle( 'candi/res_ver34_ply.pickle' )\n",
    "# alb_sim = load_pickle( 'candi/res_ver34_album.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3></h3>\n",
    "<h3></h3>\n",
    "\n",
    "\n",
    "### 후보군 중에서 추천 해주기 \n",
    "\n",
    "- 어떠한 방법으로 할까??\n",
    "\n",
    "1. 집합의 개념으로? 각영역이 추천한 노래들의 비중을 모두 1로 환산\n",
    "\n",
    "2. 단순 집계 모두 더한다음에 가장 많은 노래를 뱉기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 집합 방식의 추첨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3></h3>\n",
    "<h3></h3>\n",
    "\n",
    "\n",
    "**필터링별 데이터 받기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:50<00:00, 459.38it/s]\n",
      "100%|██████████| 23015/23015 [01:06<00:00, 343.54it/s]\n"
     ]
    }
   ],
   "source": [
    "s_can = get_candidate( s_sim , by = 'count'  )\n",
    "s_can = filter_date( s_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:49<00:00, 460.41it/s]\n",
      "100%|██████████| 23015/23015 [00:59<00:00, 383.79it/s]\n"
     ]
    }
   ],
   "source": [
    "w_can = get_candidate( w_sim , by = 'count')\n",
    "w_can = filter_date( w_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:55<00:00, 417.80it/s]\n",
      "100%|██████████| 23015/23015 [01:01<00:00, 372.14it/s]\n"
     ]
    }
   ],
   "source": [
    "sin_can = get_candidate( sin_sim, by = 'count' )\n",
    "sin_can = filter_date( sin_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:51<00:00, 445.60it/s]\n",
      "100%|██████████| 23015/23015 [01:12<00:00, 316.90it/s]\n"
     ]
    }
   ],
   "source": [
    "t_can = get_candidate( t_sim, by = 'count' )\n",
    "t_can = filter_date( t_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:50<00:00, 456.26it/s]\n",
      "100%|██████████| 23015/23015 [01:17<00:00, 297.51it/s]\n"
     ]
    }
   ],
   "source": [
    "g_sim = load_pickle( 'candi/res_ver34_gnr.pickle' )\n",
    "g_can = get_candidate( g_sim, by = 'count' )\n",
    "g_can = filter_date( g_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:49<00:00, 462.09it/s]\n",
      "100%|██████████| 23015/23015 [01:03<00:00, 363.03it/s]\n"
     ]
    }
   ],
   "source": [
    "ply_sim = load_pickle( 'candi/res_ver34_ply.pickle' )\n",
    "ply_can = get_candidate( ply_sim, by = 'count' )\n",
    "ply_can = filter_date( ply_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [01:10<00:00, 324.88it/s]\n",
      "100%|██████████| 23015/23015 [05:01<00:00, 76.28it/s] \n"
     ]
    }
   ],
   "source": [
    "alb_sim = load_pickle( 'candi/res_ver34_album.pickle')\n",
    "alb_can = get_candidate( alb_sim, by = 'count' )\n",
    "alb_can = filter_date( alb_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:56<00:00, 404.68it/s]\n",
      "100%|██████████| 23015/23015 [01:20<00:00, 285.26it/s]\n"
     ]
    }
   ],
   "source": [
    "SAG_sim = load_pickle( 'candi/res_ver37_SAG.pickle')\n",
    "SAG_can = get_candidate( SAG_sim, by = 'count' )\n",
    "SAG_can = filter_date( SAG_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [01:12<00:00, 319.50it/s]\n",
      "100%|██████████| 23015/23015 [00:56<00:00, 406.44it/s]\n"
     ]
    }
   ],
   "source": [
    "SWG_sim = load_pickle( 'candi/res_ver37_SWG.pickle')\n",
    "SWG_can = get_candidate( SWG_sim, by = 'count' )\n",
    "SWG_can = filter_date( SWG_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:54<00:00, 423.75it/s]\n",
      "100%|██████████| 23015/23015 [01:00<00:00, 378.47it/s]\n"
     ]
    }
   ],
   "source": [
    "SWAG_sim = load_pickle('candi/res_ver39_SWAG.pickle')\n",
    "SWAG_can = get_candidate( SWAG_sim, by = 'count' )\n",
    "SWAG_can = filter_date( SWAG_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:57<00:00, 398.19it/s]\n",
      "100%|██████████| 23015/23015 [01:17<00:00, 296.85it/s]\n"
     ]
    }
   ],
   "source": [
    "TSA_sim = load_pickle('candi/res_ver40_TSA.pickle')\n",
    "TSA_can = get_candidate( TSA_sim, by = 'count' )\n",
    "TSA_can = filter_date( TSA_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:59<00:00, 387.45it/s]\n",
      "100%|██████████| 23015/23015 [01:03<00:00, 361.34it/s]\n"
     ]
    }
   ],
   "source": [
    "WAT_sim = load_pickle('candi/res_ver40_WAT.pickle')\n",
    "WAT_can = get_candidate( WAT_sim, by = 'count' )\n",
    "WAT_can = filter_date( WAT_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:52<00:00, 437.44it/s]\n",
      "100%|██████████| 23015/23015 [00:52<00:00, 441.61it/s]\n"
     ]
    }
   ],
   "source": [
    "SWAT_sim = load_pickle('candi/res_ver40_SWAT.pickle')\n",
    "SWAT_can = get_candidate( SWAT_sim, by = 'count' )\n",
    "SWAT_can = filter_date( SWAT_can )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:11<00:00, 2026.60it/s]\n"
     ]
    }
   ],
   "source": [
    "candi = {}\n",
    "for i in tqdm( ply_can.keys() ):\n",
    "    candi[i] = { 'songs' : s_can[i]['songs'] + w_can[i]['songs'] + sin_can[i]['songs'] + t_can[i]['songs'] + g_can.get(i)['songs'] + ply_can[i]['songs']+alb_can[i]['songs']+SAG_can[i]['songs']+SWG_can[i]['songs']+SWAG_can[i]['songs']+TSA_can[i]['songs']+WAT_can[i]['songs']+SWAT_can[i]['songs'] ,\n",
    "                   'tags': s_can[i]['tags'] + w_can[i]['tags'] + sin_can[i]['tags'] + t_can[i]['tags'] + g_can[i]['tags'] + ply_can[i]['tags'] + alb_can[i]['tags'] + SAG_can[i]['tags'] + SWG_can[i]['tags']+SWAG_can[i]['tags']+TSA_can[i]['tags']+WAT_can[i]['tags']+SWAT_can[i]['tags']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candi = {}\n",
    "for i in tqdm( ply_can.keys() ):\n",
    "    candi[i] = { 'songs' : s_can[i]['songs'] + w_can[i]['songs'] + sin_can[i]['songs'] + t_can[i]['songs'] + g_can.get(i)['songs'] + ply_can[i]['songs'] ,\n",
    "                   'tags': s_can[i]['tags'] + w_can[i]['tags'] + sin_can[i]['tags'] + t_can[i]['tags'] + g_can[i]['tags'] + ply_can[i]['tags'] }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**후보군이 적당히 뽑혔는지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노래 하자 있는 ply1\n",
      "태그 하자 있는 ply0\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "b=0\n",
    "for i in candi:\n",
    "    if len(set(candi[i]['songs'])) < 100:\n",
    "        a += 1\n",
    "    if len(set(candi[i]['tags'])) < 10:\n",
    "        b += 1\n",
    "        \n",
    "print( f'노래 하자 있는 ply{a}')\n",
    "print( f'태그 하자 있는 ply{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:18<00:00, 1238.65it/s]\n"
     ]
    }
   ],
   "source": [
    "ply = {}\n",
    "for i in tqdm(candi):\n",
    "    ply[i] = {'songs' : [ l[0] for l in Counter(candi[i]['songs']).most_common(100) ],\n",
    "                'tags' : [l[0] for l in Counter(candi[i]['tags']).most_common(10) ]} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**인성 문제있는 플레이리스트**\n",
      "69439 : 94\n",
      "**인성 문제있는 태그**\n"
     ]
    }
   ],
   "source": [
    "print( '**인성 문제있는 플레이리스트**')\n",
    "haja_ply_song = []\n",
    "for i in ply.keys():\n",
    "    if len(ply[i]['songs']) != 100:\n",
    "        a = len(set(ply[i]['songs']))\n",
    "        haja_ply_song.append(i)\n",
    "        print( f'{i} : {a}' )\n",
    "        \n",
    "            \n",
    "haja_ply_tag = []            \n",
    "print( '**인성 문제있는 태그**' )\n",
    "for i in ply.keys():\n",
    "    if len(ply[i]['tags']) != 10:\n",
    "        a = len(ply[i]['tags'])\n",
    "        haja_ply_tag.append(i)\n",
    "        print( f'{i} : {a}' )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open( 'result/res_ver33.json' , 'w' ) as f:\n",
    "    json.dump( res , f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 응급 처치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'data/model/model_3_another.pickle' , 'rb') as f:\n",
    "    faid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_meta = pd.read_json( 'data/song_meta.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.09it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(haja_ply_song):\n",
    "    top_gnr = Counter([g for gs in song_meta.loc[ song_meta.id.isin( ply[i]['songs'] ) ].song_gn_gnr_basket for g in gs]).most_common(1)[0][0]\n",
    "    tmp = faid[top_gnr]\n",
    "    for s in ply[i]['songs']:\n",
    "        try:\n",
    "            tmp.remove(s)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    ply[i]['songs'] += tmp[: 100 - len(ply[i]['songs'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**인성 문제있는 플레이리스트**\n",
      "**인성 문제있는 태그**\n"
     ]
    }
   ],
   "source": [
    "print( '**인성 문제있는 플레이리스트**')\n",
    "haja_ply_song = []\n",
    "for i in ply.keys():\n",
    "    if len(ply[i]['songs']) != len(set(ply[i]['songs'])):\n",
    "        a = len(set(ply[i]['songs']))\n",
    "        haja_ply_song.append(i)\n",
    "        print( f'{i} : {a}' )\n",
    "       \n",
    "    \n",
    "haja_ply_tag = []            \n",
    "print( '**인성 문제있는 태그**' )\n",
    "for i in ply.keys():\n",
    "    if len(ply[i]['tags']) != len(set(ply[i]['tags'])):\n",
    "        a = len(ply[i]['tags'])\n",
    "        haja_ply_tag.append(i)\n",
    "        print( f'{i} : {a}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [] \n",
    "a = 0\n",
    "\n",
    "res = [{ 'id' : i , 'songs' : ply[i]['songs'] , 'tags' : ply[i]['tags'] } for i in ply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'result/res_ver40.json' , 'w' ) as f:\n",
    "    json.dump( res , f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
